{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sn14-query-demonstration-helper\n",
    "This notebook is meant to be used as an example to demonstrate how the subnet miners can be queried and how the validation process works. The implementation is slightly different from the normal implementation in the validators, since the logic is not 1:1 transferrable into a Jupyter Notebook. The changes are outlined in the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary modules to demonstrate the validator\n",
    "import bittensor as bt\n",
    "from llm_defender.base.protocol import LLMDefenderProtocol\n",
    "from llm_defender.core.validators.validator import LLMDefenderValidator\n",
    "from argparse import ArgumentParser\n",
    "from llm_defender.base.utils import sign_data\n",
    "from torch import argmax\n",
    "from uuid import uuid4\n",
    "from json import dumps\n",
    "from secrets import token_hex\n",
    "from time import time\n",
    "from sys import exit\n",
    "import requests\n",
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, precision_score\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup subnet-related objects required to query the network\n",
    "\n",
    "# Subnet parameters\n",
    "parser = ArgumentParser()\n",
    "parser.add_argument(\n",
    "    \"--alpha\",\n",
    "    default=0.9,\n",
    "    type=float,\n",
    "    help=\"The weight moving average scoring.\",\n",
    ")\n",
    "parser.add_argument(\"--netuid\", type=int, default=14, help=\"The chain subnet uid.\")\n",
    "\n",
    "# Define the bittensor configuration parameters here\n",
    "parser.add_argument(\"--wallet.name\", type=str, default=\"default\")\n",
    "parser.add_argument(\"--wallet.hotkey\", type=str, default=\"default\")\n",
    "parser.add_argument(\"--subtensor.network\", type=str, default=\"finney\")\n",
    "\n",
    "\n",
    "# Setup Subnet validator\n",
    "subnet_validator = LLMDefenderValidator(parser=parser)\n",
    "\n",
    "# Apply configuration\n",
    "subnet_validator.apply_config(bt_classes=[bt.subtensor, bt.logging, bt.wallet])\n",
    "\n",
    "# Initialize validator\n",
    "wallet, subtensor, dendrite, metagraph = subnet_validator.setup_bittensor_objects(\n",
    "    subnet_validator.neuron_config\n",
    ")\n",
    "subnet_validator.wallet = wallet\n",
    "subnet_validator.subtensor = subtensor\n",
    "subnet_validator.dendrite = dendrite\n",
    "subnet_validator.metagraph = metagraph\n",
    "subnet_validator.init_default_scores()\n",
    "subnet_validator.remote_logging = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions are needed resolve certain parameters before sending\n",
    "# out the query. These are not part of the standard subnet\n",
    "# implementation.\n",
    "\n",
    "\n",
    "def get_top_miner() -> bt.NeuronInfo:\n",
    "    \"\"\"This function returns the NeuronInfo for the top performing miner\n",
    "    based on incentive\"\"\"\n",
    "\n",
    "    # Get incentives and the top performing UID\n",
    "    incentives = subnet_validator.metagraph.I\n",
    "    uid = argmax(incentives)\n",
    "    print(f\"Top UID: {uid} with incentive: {incentives[uid]}\")\n",
    "\n",
    "    # Return AxonInfo based on the UID\n",
    "    neuron_info = subnet_validator.metagraph.neurons[uid]\n",
    "    return neuron_info\n",
    "\n",
    "def standard_response_processing(responses, queries, uuids, axon_to_query) -> list:\n",
    "    \"\"\"This functions performs the standard response processing and\n",
    "    returns list of processed responses\"\"\"\n",
    "\n",
    "    processed_responses = []\n",
    "    for i, entry in enumerate(responses):\n",
    "        print(\n",
    "            f\"Received non-empty response from the miner:\\n{dumps(entry.output, indent=4)}\"\n",
    "        )\n",
    "\n",
    "        # The process_response function is responsible for handling valid\n",
    "        # responses. It is executed if any one of the responses is non-empty.\n",
    "        response_data = subnet_validator.process_responses(\n",
    "            query=queries[i],\n",
    "            processed_uids=[axon_to_query.uid],\n",
    "            responses=[entry],\n",
    "            synapse_uuid=uuids[i],\n",
    "        )\n",
    "\n",
    "        processed_responses.append(response_data)\n",
    "\n",
    "        for res in response_data:\n",
    "            if subnet_validator.miner_responses:\n",
    "                if res[\"hotkey\"] in subnet_validator.miner_responses:\n",
    "                    subnet_validator.miner_responses[res[\"hotkey\"]].append(res)\n",
    "                else:\n",
    "                    subnet_validator.miner_responses[res[\"hotkey\"]] = [res]\n",
    "            else:\n",
    "                subnet_validator.miner_responses = {}\n",
    "                subnet_validator.miner_responses[res[\"hotkey\"]] = [res]\n",
    "    \n",
    "    return processed_responses\n",
    "\n",
    "def calculate_response_metrics(hotkey) -> dict:\n",
    "    \"\"\"This function calculates some standard metrics for the miner\n",
    "    responses contained in the local memory\"\"\"\n",
    "\n",
    "    data = subnet_validator.miner_responses[hotkey]\n",
    "    \n",
    "    labels = []\n",
    "    classifications = []\n",
    "\n",
    "    for i,entry in enumerate(data):\n",
    "        if entry[\"target\"] is None or entry[\"response\"][\"confidence\"] is None:\n",
    "            continue\n",
    "        labels.append(round(entry[\"target\"]))\n",
    "        classifications.append(round(entry[\"response\"][\"confidence\"]))\n",
    "\n",
    "        if labels[i] != classifications[i]:\n",
    "            print(f'Failed to classify prompt: {entry[\"prompt\"]}')\n",
    "\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(labels, classifications)\n",
    "    precision = precision_score(labels, classifications)\n",
    "    recall = recall_score(labels, classifications)\n",
    "    f1 = f1_score(labels, classifications)\n",
    "\n",
    "    res = {\n",
    "        \"hotkey\": hotkey,\n",
    "        \"count\": len(data),\n",
    "        \"metrics\": {\n",
    "            \"accuracy\": accuracy,\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall,\n",
    "            \"f1\": f1\n",
    "        },\n",
    "        \"scoring_averages\": {\n",
    "            \"total_score\": sum(entry[\"scored_response\"][\"scores\"][\"total\"] for entry in data) / len(data) if data else None,\n",
    "            \"distance_score\": sum(entry[\"scored_response\"][\"scores\"][\"distance\"] for entry in data) / len(data) if data else None,\n",
    "            \"speed_score\": sum(entry[\"scored_response\"][\"scores\"][\"speed\"] for entry in data) / len(data) if data else None,\n",
    "            \"raw_distance\": sum(entry[\"scored_response\"][\"raw_scores\"][\"distance\"] for entry in data) / len(data) if data else None,\n",
    "            \"raw_speed\": sum(entry[\"scored_response\"][\"raw_scores\"][\"speed\"] for entry in data) / len(data) if data else None,\n",
    "            \"distance_penalty\": sum(entry[\"scored_response\"][\"penalties\"][\"distance\"] for entry in data) / len(data) if data else None,\n",
    "            \"speed_penalty\": sum(entry[\"scored_response\"][\"penalties\"][\"speed\"] for entry in data) / len(data) if data else None\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return res\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup variables that are needed throughout the execution\n",
    "axon_to_query = get_top_miner()\n",
    "print(f\"Axon to query: {axon_to_query}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code block executes a normal query where the prompt is fetched\n",
    "# through the Prompt API. This is the primary query executed by the\n",
    "# validators.\n",
    "\n",
    "# Get the query to send for the miner. The query contains the metadata\n",
    "# associated with the prompt that is to be analyzed by the miners. In\n",
    "# order to query the prompt API, the hotkey must be registered in the\n",
    "# subnet 14 and have at least 20k staked TAO.\n",
    "\n",
    "# Send queries to the miner\n",
    "#\n",
    "# DANGER: There is a rate-limit of 100 requests every 10 minutes. If you\n",
    "# are executing this notebook from a host with the same IP with your\n",
    "# actual validator, you are at risk of being rate-limited.\n",
    "#\n",
    "# Please use the dataset-based approach below for queries with multiple\n",
    "# prompts. Using two prompts should be enough to be able to demonstrate\n",
    "# how the process works. The dataset-based approach below has more detailed examples\n",
    "\n",
    "n = 2\n",
    "responses = []\n",
    "queries = []\n",
    "uuids = []\n",
    "for _ in range(0, n):\n",
    "    # UUID is used to uniquely identify the request\n",
    "    synapse_uuid = str(uuid4())\n",
    "    uuids.append(synapse_uuid)\n",
    "\n",
    "    # Miner hotkeys are used to by the Prompt API to create prompts for the\n",
    "    # miners to fetch. Each prompt can be fetched only once.\n",
    "    miner_hotkeys = [axon_to_query.hotkey]\n",
    "\n",
    "    # Executing the serve_prompt method fetches the query metadata from the Prompt API\n",
    "    query = subnet_validator.serve_prompt(\n",
    "        synapse_uuid=synapse_uuid, miner_hotkeys=miner_hotkeys\n",
    "    )\n",
    "    queries.append(query)\n",
    "\n",
    "    print(f\"Query metadata:\\n{dumps(query, indent=4)}\")\n",
    "\n",
    "    # Prepare the query. The query is signed and includes a nonce, to prevent replay of validator requests\n",
    "    nonce = token_hex(24)\n",
    "    timestamp = str(int(time()))\n",
    "    signature = sign_data(\n",
    "        hotkey=subnet_validator.wallet.hotkey,\n",
    "        data=f\"{synapse_uuid}{nonce}{subnet_validator.wallet.hotkey.ss58_address}{timestamp}\",\n",
    "    )\n",
    "    miner_res = await subnet_validator.dendrite(\n",
    "        axon_to_query.axon_info,\n",
    "        LLMDefenderProtocol(\n",
    "            analyzer=query[\"analyzer\"],\n",
    "            subnet_version=subnet_validator.subnet_version,\n",
    "            synapse_uuid=synapse_uuid,\n",
    "            synapse_signature=signature,\n",
    "            synapse_nonce=nonce,\n",
    "            synapse_timestamp=timestamp,\n",
    "        ),\n",
    "        timeout=6,\n",
    "        deserialize=True,\n",
    "    )\n",
    "    responses.append(miner_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code block executes the built-in process-method for the responses\n",
    "# retrieved by the previous code block.\n",
    "\n",
    "# If all of the responses in the list of returned responses are empty\n",
    "# the validator would normally set the score for the queries to 0.0.\n",
    "if not responses or all(item.output is None for item in responses):\n",
    "    print(f\"Received empty responses: {responses}\")\n",
    "    exit(-1)\n",
    "\n",
    "processed_responses = standard_response_processing(responses, queries, uuids, axon_to_query)\n",
    "\n",
    "# After processing the responses, the validator would normally update\n",
    "# its local knowledge of the miner responses. The local knowledge of the\n",
    "# miner responses are used within the reward mechanism.\n",
    "\n",
    "print(f\"Processed response:\\n{dumps(processed_responses, indent=4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code block starts the execution of the non-standard way of\n",
    "# querying the miners. This code block creates prompts for the miners to\n",
    "# analyze rather than using the synthetic prompts generated by the\n",
    "# prompt api. This could be considered as an early prototype of the\n",
    "# subnet-api the subnet owners are building.\n",
    "\n",
    "\n",
    "def get_subnet_api(synapse_uuid, data) -> dict:\n",
    "    \"\"\"Retrieves a prompt from the prompt API\"\"\"\n",
    "\n",
    "    nonce = token_hex(24)\n",
    "    timestamp = str(int(time()))\n",
    "    signature = sign_data(\n",
    "        hotkey=subnet_validator.wallet.hotkey,\n",
    "        data=f\"{synapse_uuid}{nonce}{timestamp}\",\n",
    "    )\n",
    "\n",
    "    headers = {\n",
    "        \"X-Hotkey\": subnet_validator.wallet.hotkey.ss58_address,\n",
    "        \"X-Signature\": signature,\n",
    "        \"X-SynapseUUID\": synapse_uuid,\n",
    "        \"X-Timestamp\": timestamp,\n",
    "        \"X-Nonce\": nonce,\n",
    "        \"X-Version\": str(40),\n",
    "        # \"X-Version\": str(subnet_validator.subnet_version),\n",
    "        \"X-API-Key\": subnet_validator.wallet.hotkey.ss58_address,\n",
    "    }\n",
    "\n",
    "    prompt_api_url = \"https://subnet-api.synapsec.ai/subnet\"\n",
    "    try:\n",
    "        # get prompt\n",
    "        res = requests.post(\n",
    "            url=prompt_api_url, headers=headers, data=dumps(data), timeout=12\n",
    "        )\n",
    "        # check for correct status code\n",
    "        if res.status_code == 201:\n",
    "            # get prompt entry from the API output\n",
    "            prompt_entry = res.json()\n",
    "            # check to make sure prompt is valid\n",
    "            bt.logging.trace(f\"Loaded remote prompt to serve to miners: {prompt_entry}\")\n",
    "            return prompt_entry\n",
    "\n",
    "        else:\n",
    "            bt.logging.warning(\n",
    "                f\"Unable to get prompt from the Prompt API: HTTP/{res.status_code} - {res.json()}\"\n",
    "            )\n",
    "    except requests.exceptions.ReadTimeout as e:\n",
    "        print(e)\n",
    "        bt.logging.error(f\"Prompt API request timed out: {e}\")\n",
    "    except requests.exceptions.JSONDecodeError as e:\n",
    "        print(e)\n",
    "        bt.logging.error(f\"Unable to read the response from the prompt API: {e}\")\n",
    "    except requests.exceptions.ConnectionError as e:\n",
    "        print(e)\n",
    "        bt.logging.error(f\"Unable to connect to the prompt API: {e}\")\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        bt.logging.error(f\"Generic error during request: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup prompts and labels to be queried. The dataset is used as a\n",
    "# reference contains prompts that have already been served to the\n",
    "# network, so it is likely a top miner is pretty good at classifying the\n",
    "# prompts.\n",
    "dataset = load_dataset(\"synapsecai/synthetic-prompt-injections\")\n",
    "test_dataset = dataset[\"test\"]\n",
    "\n",
    "dataset = test_dataset.shuffle(seed=42)\n",
    "samples = test_dataset.select(range(50))\n",
    "# Now, separate the text and prompts into two lists\n",
    "prompts = [sample['text'] for sample in samples]\n",
    "labels = [1 if sample['label'] == 'malicious' else 0 for sample in samples]\n",
    "\n",
    "# Store miner responses and queries in a list\n",
    "responses = []\n",
    "queries = []\n",
    "uuids = []\n",
    "\n",
    "# Send queries to miners\n",
    "for i,_ in enumerate(prompts):\n",
    "    \n",
    "    # UUID is used to uniquely identify the request\n",
    "    synapse_uuid = str(uuid4())\n",
    "    uuids.append(synapse_uuid)\n",
    "    \n",
    "    # Prepare data object to push to Prompt API\n",
    "    data = {\n",
    "        \"hotkey\": axon_to_query.hotkey,\n",
    "        \"prompt\": prompts[i],\n",
    "        \"label\": str(labels[i]),\n",
    "        \"analyzer\": \"Prompt Injection\",\n",
    "    }\n",
    "    \n",
    "    # Push prompt to prompt API and get the query metadata\n",
    "    query = get_subnet_api(synapse_uuid=synapse_uuid, data=data)\n",
    "    queries.append(query)\n",
    "\n",
    "    print(f\"Query metadata:\\n{dumps(query, indent=4)}\")\n",
    "\n",
    "    # Prepare the query. The query is signed and includes a nonce, to prevent replay of validator requests\n",
    "    nonce = token_hex(24)\n",
    "    timestamp = str(int(time()))\n",
    "    signature = sign_data(\n",
    "        hotkey=subnet_validator.wallet.hotkey,\n",
    "        data=f\"{synapse_uuid}{nonce}{subnet_validator.wallet.hotkey.ss58_address}{timestamp}\",\n",
    "    )\n",
    "\n",
    "    miner_res = await subnet_validator.dendrite(\n",
    "        axon_to_query.axon_info,\n",
    "        LLMDefenderProtocol(\n",
    "            analyzer=query[\"analyzer\"],\n",
    "            subnet_version=subnet_validator.subnet_version,\n",
    "            synapse_uuid=synapse_uuid,\n",
    "            synapse_signature=signature,\n",
    "            synapse_nonce=nonce,\n",
    "            synapse_timestamp=timestamp,\n",
    "        ),\n",
    "        timeout=6,\n",
    "        deserialize=True,\n",
    "    )\n",
    "    responses.append(miner_res)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not responses or all(item.output is None for item in responses):\n",
    "    print(f\"Received empty responses: {responses}\")\n",
    "    exit(-1)\n",
    "\n",
    "processed_responses = standard_response_processing(responses, queries, uuids, axon_to_query)\n",
    "\n",
    "# After processing the responses, the validator would normally update\n",
    "# its local knowledge of the miner responses. The local knowledge of the\n",
    "# miner responses are used within the reward mechanism.\n",
    "\n",
    "print(f\"Processed response:\\n{dumps(processed_responses, indent=4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print miner metrics from the stored miner responses\n",
    "metrics = calculate_response_metrics(hotkey=axon_to_query.hotkey)\n",
    "print(dumps(metrics,indent=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
