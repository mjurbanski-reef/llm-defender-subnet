"""This module implements the YARA engine for the llm-defender-subnet"""

from os import path, makedirs
from glob import glob
import bittensor as bt
import yara
from llm_defender.base.engine import BaseEngine


class YaraEngine(BaseEngine):
    """
    This class implements the YARA engine.
    
    YARA is a powerful pattern matching tool that can be used to analyze
    strings based on boolean operators and other logical patterns. As a
    part of prompt injection analyzer, the YARA engine is used to detect
    well known prompt injections and other patterns within the inputs
    that could be an indication of prompt injections.

    The detection logic is described within the rules and in order to
    fine-tune this engine, you should add additional rules within the
    yara_rules directory.
    
    Attributes:
        prompt:
            An instance of str which describes the prompt for the YaraEngine 
            to analyze. Default is None.
        name:
            An instance of str which describes the name for the YaraEngine. 
            Default is 'engine:yara'
        cache_dir: 
            The cache directory allocated for the engine.
        compiled:
            An instance of str depicting the path for the compiled YARA rules 
            (based on the cache_dir attribute).
        rules:
            An instance of str depicting the path for the YARA rules (based 
            on the cache_dir attribute).
        output: 
            A dict instance which represents the output of the YARA analysis 
            for a prompt injection attack. This attribute will always have the 
            flag 'outcome', for which the possible strings associated will be 
            either 'RuleMatch' or 'NoRuleMatch'.
            
            If the 'outcome' flag has the associated str value 'RuleMatch', 
            then there will also be the flag 'meta' in the output attribute. 

            Please reference the _populate_data() method for more information 
            on how this attribute is generated. 
        confidence:
            A float instance displaying the confidence score that a given prompt 
            is a prompt attack for an LLM. This value ranges from 0.0 to 1.0.

            Please reference the _calculate_confidence() method for more details 
            on how this value is generated. 

    Methods:
        __init__():
            Initializes the name, prompt, compiled & rules attributes for the 
            YaraEngine.
        _calculate_confidence():
            Generates a confidence score for a prompt injection attack, ranging 
            from 0.0 (SAFE) 
            to 1.0 (MALICIOUS) for the YaraEngine.
        _populate_data():
            Takes in the results from the YARA analysis and properly formats 
            the outputs into a dict instance which can be used by the YaraEngine 
            to generate a confidence score.
        prepare():
            Checks cache directory, making it if it does not already exist, then 
            compiles YARA rules.
        initialize():
            Prepares the YARA engine and loads the rules into it. Outputs the YARA
            rules unless an error is raised.
        execute():
            Generates the YARA analysis output and confidence score for a given 
            prompt being a prompt injection attack.
    """
    def __init__(self, prompt: str=None, name: str = "engine:yara"):
        """
        Initializes the name, prompt, compiled & rules attributes for the YaraEngine.

        Arguments:
            prompt:
                An instance of str which describes the prompt for the YaraEngine to analyze.
                Default is None.
            name:
                An instance of str which describes the name for the YaraEngine. Default is
                'engine:yara'

        Returns:
            None
        """
        super().__init__(name=name)

        self.prompt = prompt
        self.compiled = f"{self.cache_dir}/compiled_rules"
        self.rules = f"{path.dirname(__file__)}/yara_rules/*.yar"

    def _calculate_confidence(self):
        """
        Generates a confidence score for a prompt injection attack, ranging 
        from 0.0 (SAFE) to 1.0 (MALICIOUS) for the YaraEngine.

        Arguments:
            None

        Returns:
            float:
                This float instance has a range from 0.0 to 1.0 representing the 
                confidence score generated by the YaraEngine that the prompt 
                specified by the prompt attribute is a prompt injection attack. 
                The value 0.5 will be returned by default if the 'outcome' flag
                in the output attribute is NOT 'NoRuleMatch'
            
        Raises:
            ValueError:
                The ValueError is raised if the YARA rule accuracy is out of bounds.
        """
        if self.output["outcome"] != "NoRuleMatch":
            match_accuracies = []
            for match in self.output["meta"]:
                if float(match["accuracy"]) < 0.0 or float(match["accuracy"]) > 1.0:
                    raise ValueError(f'YARA rule accuracy is out-of-bounds: {match}')
                match_accuracies.append(float(match["accuracy"]))

            return 1.0 * max(match_accuracies)
        return 0.5

    def _populate_data(self, results):
        """
        Takes in the results from the YARA analysis and properly formats the outputs into a dict
        instance which can be used by the YaraEngine to generate a confidence score.

        Arguments:
            results:
                The output of yara.rules.match(). 

                Please reference the execute() method for more information on how this is generated 
                before it is passed through the _populate_data() method.

        Returns:
            A dict instance which represents the output of the YARA analysis for a prompt injection
            attack. This attribute will always have the flag 'outcome', for which the possible strings 
            associated will be either 'RuleMatch' or 'NoRuleMatch'.
            
            If the 'outcome' flag has the associated str value 'RuleMatch', then there will also be
            the flag 'meta' in the output attribute. 
        """
        if results:
            return {
                "outcome": "RuleMatch",
                "meta": [result.meta for result in results],
            }
        return {"outcome": "NoRuleMatch"}

    def prepare(self) -> bool:
        """
        Checks cache directory, making it if it does not already exist, then
        compiles YARA rules.

        Arguments:
            None

        Returns:
            True, unless an error is raised in which case None will be returned.

        Raises:
            OSError:
                The OSError is raised if the YaraEngine was unable to create a 
                cache directory using its cache_dir attribute, or if the YARA rules 
                were unable to be read correctly.
            FileNotFoundError:
                The FileNotFoundError is raised if the compiled YARA rules were unable 
                to be located.
            yara.SyntaxError
                yara.SyntaxError is raised if there was a syntax error when compiling 
                the YARA rules.
            yara.Error
                yara.Error is raised if the YARA rules were unable to be compiled.
        """
        # Check cache directory
        if not path.exists(self.cache_dir):
            try:
                makedirs(self.cache_dir)
            except OSError as e:
                raise OSError(f"Unable to create cache directory: {e}") from e

        # Compile YARA rules
        try:
            files = glob(self.rules)
            yara_rules = {}
            for file in files:
                with open(file, "r", encoding="utf-8") as f:
                    yara_rules[file] = f.read()

            compiled_rules = yara.compile(sources=yara_rules)
            compiled_rules.save(self.compiled)

            if not path.isfile(self.compiled):
                raise FileNotFoundError(f'Unable to locate compiled YARA rules: {e}')

            return True
        except OSError as e:
            raise OSError(f"Unable to read YARA rules: {e}") from e
        except yara.SyntaxError as e:
            raise yara.SyntaxError(f"Syntax error when compiling YARA rules: {e}") from e
        except yara.Error as e:
            raise yara.Error(f"Unable to compile YARA rules: {e}") from e

    def initialize(self) -> yara.Rules:
        """
        Initializes the YARA engine and loads the rules into it. Outputs the YARA rules 
        unless an error is raised.
        
        Arguments:
            None

        Returns:
            rules:
                A yara.Rules instance that defines the YARA rules for the YaraEngine. 
                It is outputted by calling yara.load(self.compiled).

        Raises:
            yara.Error
                yara.Error is raised if the YARA engine was unable to be prepared, or
                if the YARA rules were unable to be loaded in.
        """
        if not path.isfile(self.compiled):
            bt.logging.warning("Compiled YARA rules not found. Running preparation mid-flight.")
            if not self.prepare():
                raise yara.Error('Unable to prepare YARA engine')
        try:
            rules = yara.load(self.compiled)
            return rules
        except yara.Error as e:
            raise yara.Error(f"Unable to load rules: {e}") from e
    
    def execute(self, rules: yara.Rules) -> bool:
        """
        Generates the YARA analysis output and confidence score for a given 
        prompt being a prompt injection attack.

        Arguments:
            rules:
                A yara.Rules instance that defines the YARA rules for the 
                YaraEngine.

        Returns:

        Raises:
            ValueError:
                The ValueError is raised if the input is empty or the input 
                is not a str instance.
            yara.TimeoutError:
                yara.TimeoutError is raised if YARA matching times out or 
                returns an error.
        """
        if not self.prompt:
            raise ValueError('Cannot execute engine with empty input')

        if not isinstance(self.prompt, str):
            raise ValueError(f'Input must be a string. The type for the input {self.prompt} is: {type(self.prompt)}')
        
        try:
            results = rules.match(data=self.prompt)
        except yara.TimeoutError as e:
            raise yara.TimeoutError(f'YARA matching timed out: {e}') from e
        except yara.Error as e:
            raise yara.TimeoutError(f'YARA matching returned an error: {e}') from e

        self.output = self._populate_data(results)
        self.confidence = self._calculate_confidence()

        bt.logging.debug(f"YARA engine executed (Confidence: {self.confidence} - Output: {self.output})")
        return True